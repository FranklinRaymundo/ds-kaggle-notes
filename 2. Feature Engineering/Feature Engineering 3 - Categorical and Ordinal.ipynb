{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "# # Bigger font\n",
    "sns.set_context(\"talk\")\n",
    "# # Figure size\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 4\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinal vs Categorical\n",
    "\n",
    "Ordinal features are **ordered categorical features**, and there won't be an equal separation between consecutive values.\n",
    "\n",
    "They can be presented as already encoded values.  \n",
    "For example, in the titanic dataset, \"Pclass\" is an ordinal feature.\n",
    "\n",
    "## PREPROCESSING\n",
    "\n",
    "## 1. Tree-based models\n",
    "\n",
    "**Label Encoding/Integer Encoding** = Mapping of unique values to numbers.  \n",
    "It works well with tree-based models.\n",
    "\n",
    "- For example, \"red\" is 1, \"yellow\" is 2, and \"green\" is 3.\n",
    "- This one seems sufficient for **ordinal data**; for example, a “place” variable with the values like “first”, “second” and “third“.\n",
    "- It can be used when the number of categorical features is either small or huge unlike when using one-hot-encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of label encoding\n",
    "#### a. Alphabetical (sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    S\n",
      "1    C\n",
      "2    S\n",
      "3    S\n",
      "4    S\n",
      "5    Q\n",
      "Name: Embarked, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "titanic_train = pd.read_csv(\"A. Datasets/data/titanic_train.csv\")\n",
    "titanic_train['Embarked'].dropna(inplace=True)\n",
    "print(titanic_train['Embarked'].head(6))\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "encoder.fit(titanic_train['Embarked'].values)\n",
    "encoder.transform(['S', 'C', 'Q'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Order of appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(titanic_train['Embarked'].factorize())\n",
    "pd.factorize(['S', 'C', 'Q'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Non-tree-based models\n",
    "\n",
    "#### a. Frequency encoding\n",
    "\n",
    "- It maps values to their frequencies.\n",
    "- This one may actually help both **tree-based** and **non-tree-based models**.\n",
    "\n",
    "For example, if frequency of category is correlated with the target value,  a linear model will utilize this dependency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.722783\n",
      "1    0.188552\n",
      "2    0.722783\n",
      "3    0.722783\n",
      "4    0.722783\n",
      "5    0.086420\n",
      "Name: Embarked, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "encoding = titanic_train.groupby('Embarked').size()\n",
    "encoding = encoding/len(titanic_train)\n",
    "freq_enc = titanic_train['Embarked'].map(encoding).head(6)\n",
    "print(freq_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If they are multiple categories with the same frequency, use rankdata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5, 1.5, 3. ])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import rankdata\n",
    "rankdata([0.3, 0.3, 0.4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. One Hot Encoding\n",
    "\n",
    "It is \"The Standard Approach for Categorical Data\"\n",
    "\n",
    "- Useful when there's no ordinal relationship though some use it even so (I need to go further on this).\n",
    "- Some sources suggest **not to do it for variables taking more than 15 categories**.\n",
    "- It is already scaled.\n",
    "- If there are a few Numeric Features and many One-hot-encoding features, it would be hard for tree-based methods. This will slow down their efficiency and precision.\n",
    "- If the feature has too many categories, there will be too many columns with **few non-zero values ----> store those values efficiently with Space Matrices** (often useful with categorical or text data). XGBoost, LightGBM, sklearn work with sparce matrices directly.\n",
    "\n",
    "- It does dummy coding.\n",
    "- **Dummy coding** = process of coding a categorical variable into dichotomous variables (variables coded as 0 or 1).\n",
    "- **Dummy variables** = binary variables often called dummy in other fields such as statistics.\n",
    "\n",
    "An example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df = {'F': [1, 2, 3],\n",
    "           'target': [1, 0, 1]\n",
    "          }\n",
    "df = pd.DataFrame(dict_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without this procedude, only a tree-based model would do well.\n",
    "\n",
    "![](images/whyonehotencoding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a linear model to work well, there should be linear a relationship between the feature(s) and the target. Then, the model can find a **LINEAR DEPENDENCY**.\n",
    "\n",
    "**Linear a relationship** = when plotted on a graph a straight line can be traced.\n",
    "\n",
    "The feature \"F\"  is turned into 3 different features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          F  target\n",
       "F       1.0     0.0\n",
       "target  0.0     1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In that case, there is no linear correlation, so we **use one-hot-encoding**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  2  3  target\n",
       "0  1  0  0       1\n",
       "1  0  1  0       0\n",
       "2  0  0  1       1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_onehot = pd.concat([pd.get_dummies(df.F), df.target], axis=1)\n",
    "df_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1    2    3  target\n",
       "1       1.0 -0.5 -0.5     0.5\n",
       "2      -0.5  1.0 -0.5    -1.0\n",
       "3      -0.5 -0.5  1.0     0.5\n",
       "target  0.5 -1.0  0.5     1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_onehot.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now theres's more linear correlation than before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE GENERATION\n",
    "\n",
    "This will be the first basic feature generation type.\n",
    "\n",
    "#### a. Feature interaction b/w categorical features\n",
    "\n",
    "- This is useful for **non-tree-based models**.\n",
    "- The model will be able to consider interactions b/w features.\n",
    "\n",
    "If target depends on both sex and pclass, then we can make a model consider every possible combination of these features by **concatenating strings** and then applying **one-hot-encoding**.\n",
    "\n",
    "![](images/feature_interaction.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Number of occurrences\n",
    "\n",
    "A new column, the number of occurrences of a category can be added."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
